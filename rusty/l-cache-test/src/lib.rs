// Include the constant generated by build.rs
include!(concat!(env!("OUT_DIR"), "/constants.rs"));

// A large dataset size, 64M
const DATA_SIZE: usize = 64 * 1024 * 1024;

// i32 is 4 byte, cpu load per cache line size which is 128 bytes.
// 128 / 4 = 32, so cpu load 32 elements per time
// so the next two functions runtime not different a lot.

pub fn sequential_access_step4(data: &mut [i32]) {
    for i in (0..data.len()).step_by(4) {
        data[i] = 1;
    }
}

pub fn sequential_access_step16(data: &mut [i32]) {
    for i in (0..data.len()).step_by(16) {
        data[i] = 1;
    }
}

pub fn cache_line_hit_with_increment(count: usize, increment: usize) {
    let size = count * increment;
    let mut data: Vec<i32> = vec![0; size];

    for j in (0..size).step_by(increment) {
        data[j] += 1;
    }
}

pub fn matrix_iter_row() -> i32 {
    let col_num = 512;
    let row_num = 1024;
    let matrix = vec![vec![0i32; col_num]; row_num];

    let mut sum: i32 = 0;
    for r in 0..row_num {
        for c in 0..col_num {
            sum = sum.wrapping_add(matrix[r][c]);
        }
    }
    sum
}

pub fn matrix_iter_col() -> i32 {
    let col_num = 512;
    let row_num = 1024;
    let matrix = vec![vec![0i32; col_num]; row_num];

    let mut sum: i32 = 0;
    for c in 0..col_num {
        for r in 0..row_num {
            sum = sum.wrapping_add(matrix[r][c]);
        }
    }
    sum
}

// Helper to create data for the benchmark
pub fn create_data() -> Vec<i32> {
    vec![0; DATA_SIZE]
}
